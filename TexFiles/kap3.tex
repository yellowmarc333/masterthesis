\documentclass[a4paper,11pt]{article}

\parindent0cm
\usepackage
[backend=biber,style=apa,sorting=nyt]
{biblatex}
\addbibresource{literature.bib}

\usepackage[utf8]{inputenc}
\usepackage{csquotes}
\usepackage{array}
\usepackage{dirtytalk}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{color}
\usepackage{layouts}
% printing the textsize used
% \printinunitsof{cm}
% \prntlen{\textwidth}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage[ngerman]{babel}
\usepackage[left=3cm,right=2.5cm,top=2cm,bottom=2cm]{geometry}
\renewcommand{\baselinestretch}{1.5}\normalsize % Zeilenabstand 1.5




\begin{document}

\section{Statistische Methoden}

Dieses Kapitel ist in $3$ Abschnitte unterteilt. Zuerst werden die zur Bewertung der Modelle herangezogenen Gütemaße beschrieben. Es folgt die Darlegung der verschiedenen Methoden zur numerischen Repräsentation von Wörtern. Zuletzt folgt die ausführliche Beschreibung der in dieser Arbeit benutzten \textit{machine-learning} Algorithmen.

\subsection{Gütemaße zur Evaluation der Modelle}\label{kap:guetemass}

Die Bewertung der Modelle erfolgt über verschiedene Kennzahlen. Einige davon werden unter Verwendung der \textit{confusion matrix} (oder auch Klassifikationsmatrix) berechnet. Wird das Modell auf die Testdaten angewandt und für jeden Datenpunkt eine Kategorie vorhergesagt, so stellt die in Tabelle \ref{tab:confusionMatrix} abgebildete Matrix die resultierenden Richtig- und Fehlklassifikationen für $C$ Klassen dar.

\begin{table}[ht]
\begin{center}
\begin{tabular}{|c|ccc|c|}
  \hline
 & \multicolumn{3}{|c|}{Prognostizierte Klasse} &  \\
Wahre Klasse & Kategorie $c_1$ & ...  & Kategorie $c_C$ & Zeilensumme  \\ 
  \hline
Kategorie $c_1$ & $h_{11}$ & $\hdots$ & $h_{1C}$ & $\sum_{j=1}^C h_{1j}$\\
$\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ & $\vdots$ \\
Kategorie $c_C$ & $h_{C1}$ & $\hdots$ & $h_{CC}$ & $\sum_{j=1}^C h_{Cj}$\\
\hline
Spaltensumme & $\sum_{i=1}^C h_{i1}$ & $\vdots$ & $\sum_{i=1}^C h_{iC}$ & 
$N = \sum_{i=1}^C \sum_{j=1}^C h_{ij}$\\
   \hline
\end{tabular}

  \caption{Übersicht über eine \textit{confusion matrix}  für $C$  Klassen (vgl. \cite{backhaus}, S. 238)}  
  \label{tab:confusionMatrix}
\end{center}
\end{table}

Die absoluten Häufigkeiten $h_{ij}$ stehen für die Anzahl der Beobachtungen aus der wahren Klasse $i$, für die die Klasse $j$ prognostiziert wurde. Summiert man alle Einträge der Matrix, so erhält man die Anzahl der Beobachtungen $N$. Aus der \textit{confusion matrix} können folgende Größen identifiziert werden: Die \textit{true-positives} der Klasse $i$, $tp_i = h_{ii}$ sind alle Beobachtungen, die Klasse $i$ zugehörig sind und auch in selbige Klassifiziert wurden. Die Beobachtungen, die in Klasse $i$ klassifiziert wurden, aber einer anderen wahren Klasse zugehörig sind, bezeichnet man als \textit{false-positives} $fp_i = \sum_{j = 1}^C h_{ji} - h{ii}$. Als \textit{true-negatives} $tn_i \sum_{j = 1}^C h_{ij} - h{ii}$ werden die Beobachtungen bezeichnet, die der Klasse $i$ zugehörig sind, aber in eine andere Kategorie falsch klassifiziert werden. Letztlich sind \textit{false-negatives} $fn_i = N - (tp_i + fp_i + tn_i)$ die Datenpunkte, die nicht Kategorie $i$ angehören und für die auch nicht Klasse $i$ prognostiziert wird (vgl. \cite{sokolova}, S. 3). Unter Kenntnis der $4$ Häufigkeiten können nun verschiedene Gütemaße berechnet werden. 


Die \textit{accuracy} berechnet sich analog zur binären Klassifikation aus 
\[ accuracy = \frac{\sum_{i=1}^C tp_i}{N},  \]
ist also der Anteil der richtig klassifizierten Beobachtungen an allen Beobachtungen. Dieses Maß ist jedoch gerade bei unbalancierten Klassifikationsproblemen nicht ideal, da große Klassen stark favorisiert werden und ein Modell schon eine hohe Güte erzielen kann, indem es alle Beobachtungen der größten Klasse zuordnet (vgl. \cite{backhaus}, S.239). Es folgen die Maße \textit{precision}, \textit{recall} und darauf aufbauende Kennzahlen, welche bei unterschiedlichen Klassengrößen geeigneter sind. Es wird von einer hohen \textit{precision} der Klasse $i$ gesprochen, wenn nach Prognose in Klasse $i$ ein hoher Anteil dieser Beobachtungen auch tatsächlich aus derselben Kategorie stammt. Wiederum hat das Modell bezüglich Klasse $i$ einen hohen \textit{recall}, falls von den Beobachtungen der wahren Klasse $i$ auch ein hoher Anteil in Klasse $i$ eingeordnet wird.
In der \textit{multiclass}-Klassifikation kann ein Gütemaß für das komplette Modell über \textit{micro-averaging} (mit $\mu$ indiziert) oder \textit{macro-averaging} (mit $M$ indiziert) über alle Klassen berechnet werden. Es sind dann 
\[ precision_{\mu} = \frac{\sum_{i = 1}^C tp_i}{\sum_{i = 1}^C (tp_i + fp_i)}, \hspace{1cm} recall_{\mu} = \frac{\sum_{i = 1}^C tp_i}{\sum_{i = 1}^C (tp_i + fn_i)},\]
\[ precision_M = \frac{\sum_{i = 1}^C \frac{tp_i}{tp_i + fp_i} }{l}, \hspace{1cm} recall_M = \frac{\sum_{i = 1}^C \frac{tp_i}{tp_i + fn_i} }{l}\]
die Gütemaße für das gesamte Modell. Ein Maß, dass \textit{precision} und \textit{recall} kombiniert ist der \textit{fscore}. Mit der unterschiedlichen Durchschnittsbildung ergeben sich
\[ f\beta score_{\mu} = \frac{(\beta^2+1) precision_{\mu} recall_{\mu}}{\beta^2 precision_{\mu}+ recall_{\mu}}, \hspace{1cm} f\beta score_{M} = \frac{(\beta^2+1) precision_{M} recall_{M}}{\beta^2 precision_{M}+ recall_{M}} . \]
Hierbei ist anzumerken, dass $f\beta score_{\mu}$ Klassen mit vielen Beobachtungen in der Güte begünstigt während für $f\beta score_M$ alle Kategorien gleich wichtig sind  (vgl. \cite{sokolova}, S.3ff). Der Parameter $\beta$ gibt in den Formeln an, was für ein Gewicht \textit{recall} im Verhältnis zu \textit{precision} einnimmt.
Wie bei dem \textit{f1score} Maß einer binären Klassifikation wird hier $\beta = 1$ gesetzt. \textit{recall} und \textit{precision} besitzen also identische Wichtigkeit. In der statistischen Auswertung in Kapitel \ref{Kap:statAus} werden beide Kennzahlen zur Bewertung der Modelle herangezogen.\\

Ein weiteres Maß, um die Güte eines Multiklassifikationsproblems zu bewerten ist die \textit{categorical cross entropy}. Diese berechnet sich aus

\[ CE = -\sum_{i=1}^N \sum_{j = 1}^C y_{ij} log(p_i(c_j)) \]

(vgl. \cite{murphy}, S.571) wobei $y_{ij} \in \{0,1\} \hspace{0.2cm} \forall i, j = 1,...,N$ indiziert, ob die Beobachtung $i$ der wahren Klasse $j$ zugehörig ist und $p_i(c_j)$ die vom Modell vorgegebene Wahrscheinlichkeit ist, dass Beobachtung $i$ zu Klasse $j$ gehört. Da $y_{ij}$ immer $0$ für alle falschen vorhergesagten Klassen ist, entspricht $CE$ der negativen Summe der logarithmierten Wahrscheinlichkeiten der wahren Klassen über alle Beobachtungen. So wird eine geschätzte Wahrscheinlichkeit nahe $0$ für die wahre Klasse stark bestraft und eine hohe Wahrscheinlichkeit trotz einer Fehlklassifikation weniger bestraft. Je sicherer sich das Modell für die wahren Kategorien ist, desto niedrigere Werte wird dieses Gütemaß annehmen (vgl. \cite{proMachine}, S. 72). 
Dabei gilt es die \textit{cross entropy} zu minimieren. Sie nimmt ihr Minimum bei $0$ im Idealfall an, wenn für alle Beobachtungen eine Wahrscheinlichkeit von $1$ für die wahre Klasse prognostiziert wird. Die $CE$ wird oft als Verlustfunktion für die Modellanpassung auf den Trainingsdaten verwendet, wie zum Beispiel bei \textit{xgBoost} und den \textit{deep learning} Algorithmen aus Kapitel \ref{kap:neuralNets}.\\
\\
Die in diesem Abschnitt beschriebenen Maße können sowohl auf den Trainingsdaten als auch auf den Testdaten evaluiert werden. Ein Vergleich der Modelle erfolgt natürlich über die Evaluation auf den ungesehenen Testdaten. Dabei werden in erster Linie $accuracy$, $CE$, $f1score_\mu$ und $f1score_M$ genutzt. Ersteres ist trotz seiner Nachteile bei unausgeglichenen Klassengrößen sehr einfach zu interpretieren und soll deshalb mit aufgelistet werden.


\subsection{Methoden zur numerischen Repräsentation der Wörter} \label{kap:3.1Wordemb}

Das Extrahieren von Informationen aus Texten ist keine triviale Aufgabe, für die es viele Methoden gibt. In diesem Abschnitt werden einige Methoden aufgezählt, die in dieser Thesis zum Einsatz kommen.


\subsubsection{\textit{bag-of-words} und \textit{term frequency inverse document frequency}} \label{Kap:Tfidf}

Bei diesen Methoden wird zuerst für den gesamten Textkorpus ein Vokabular gebildet, das für jedes vorkommende Wort die absolute Häufigkeit des Vorkommens sowie die Anzahl der Dokumente (ein Dokument ist ein Datenpunkt, also eine Schlagzeile) enthält, in der das Wort vorkommt. Aus diesem Vokabular wird anschließend die Matrix $dtm$ (\textit{document-term-matrix}) geformt, die für jede der $N$ Beobachtungen eine Zeile und für jede der $V$ Wörter im Vokabular eine Spalte enthält. Die Einträge der Matrix bestehen aus Werten, die das Aufkommen der Wörter beschreiben. Im simplen \textit{bag-of-words} (kurz: \textit{bow}) Ansatz ist $dtm_{ij} = f_{d_i t_j}$ die Anzahl von Wort $t_j$ in Dokument $d_i$ (vgl. \cite{deepEssentials} S. 117f). Es gibt einige Wörter wie \textit{the} oder \textit{and}, die häufig vorkommen aber eventuell nicht wichtig sind. Diese \textit{stopwords} können für die \textit{bow} Methode entfernt werden. Dies muss aber nicht erfolgen, da manche \textit{stopwords} in einen Kategorien häufiger vorkommen können als in anderen.
Im \textit{bow} wird nur gezählt, wie oft ein Wort absolut vorkommt, dabei wird aber nicht berücksichtigt, dass manche Wörter in einigen Dokumenten eine höhere Bedeutung haben können als in anderen. \\

Ein Ansatz, der diese Problematik berücksichtigt ist \textit{term frequency inverse document frequency} (kurz: \textit{tf-idf}). Hierbei werden die Einträge $dtm_{ij}$ bei häufig benutzten Ausdrücken verringert und erhöht für Wörter, die insgesamt selten benutzt werden (vlg. \cite{textMiningR} S.29). Die \textit{tf-idf} für das Dokument $d_i$ und das Wort $t_j$ berechnet sich aus 
\[tfidf(d_i, t_j) = tf(d_i,t_j) \cdot idf(t_j) . \]
Sowohl für die \textit{term-frequency} $tf$ als auch für die \textit{inverse-document-frequency} $idf$ gibt es verschiedene Möglichkeiten zur Berechnung, wobei in dieser Thesis folgende Formeln genutzt werden.
Die \textit{augmented-term-frequency}

\[tf(d_i,t_j) = 0.5 +  0.5 \cdot \frac{f_{d_i t_j}}{max \{ f_{d_i t_j'}: t_j' \in d_i \}} \].

berücksichtigt eine Verzerrung bei längeren Dokumenten, indem durch das Maximum der vorkommenden Wörter in dem Dokument dividiert wird. Der Summand $0.5$ und der Multiplikator $0.5$ dienen der Normalisierung. Für die \textit{inverse document frequency} ist der Quotient zwischen der Anzahl der Dokumente $N$ im Korpus und der Anzahl der Dokumente, die das Wort enthalten, ein geeignetes Maß (vgl. \cite{deepEssentials} S. 118):

\[idf(t_j) = log(\frac{N}{\# \{d_i: t_j \in d_i \}}) .\]

Die Umsetzung im Programmiercode erfolgte mit dem \texttt{R}- Paket \texttt{text2vec} (\cite{text2vec}).\\

Unter Nutzung von sowohl \textit{bow} als auch \textit{tfidf} für die Repräsentation von Wörtern vernachlässigt man die Reihenfolge in den Dokumenten (vgl. \cite{deepEssentials} S. 117). Die nachfolgend beschriebenen Methoden berücksichtigen hingegen die Reihenfolge der Wörter in einem Satz.


\subsubsection{\textit{GloVe: Global vectors for representation of words}} \label{Kap:Glove}

Eine weitere Methode zur numerischen Repräsenation von Texten sind \textit{word embeddings}, bei denen Wörter zu Vektoren fester Länge mit numerischen Werten kodiert werden. Mittlerweile haben sich \textit{word embeddings} als präferierte Methode für alle Bereiche der Sprachverarbeitung im \textit{machine-learning} durchgesetzt. Die beiden bekanntesten Methoden um \textit{word embeddings} zu generieren sind \textit{word2vec} und \textit{GloVe} (vgl. \cite{keras}, S. 139). Obwohl \textit{word2vec} auf dem Lernen durch ein neuronales Netz basiert und \textit{GloVe} auf der Zählung des Vorkommens von Wörtern im Kontext aufbaut, sind die beiden Verfahren von der grundsätzlichen Herangehensweise und den Resultaten ähnlich. Beide Methoden konstruieren einen Vektorraum, in dem die Position eines Worts durch den Kontext bestimmt wird, in dem das Wort im Textkorpus auftritt.
\textit{GloVe} liefert im Vergleich zu \textit{word2vec} generell etwas bessere Resultate und ist mit Paralellisierung schneller zu berechnen (vgl. \cite{keras}, S. 156). Aus diesen Gründen wird in dieser Thesis \textit{GloVe} verwendet und im Folgenden beschrieben. \\
Die Methode nutzt ein unüberwachtes Lernen zur Konstruktion der Vektoren. Zuerst wird eine Matrix $R$ konstruiert, die so viele Zeilen enthält, wie das Vokabular Wörter besitzt. Die Spalten stehen ebenso für die Wörter des Vokabulars, allerdings als Kontext verstanden. In den Einträgen der Matrix stehen nun die Häufigkeit des Vorkommens der Wörter (Zeilen) im jeweiligen Kontext (Spalten). Ob ein Wort im Kontext vorkommt, ist so zu verstehen, dass es in einem vom Anwender wählbaren Fensterbereich um das Kontextwort enthalten ist. Zur Verdeutlichung sei folgender Satz gegeben: \textit{these quotes from kids are hilarious, adorable and oddly insightful}. So kommt für einen symmetrischen Bereich von $2$ dass Wort \textit{hilarious} im Kontext von \textit{kids} einmal vor, wobei \textit{insightful} nicht im Kontext von \textit{kids} vorkommt. 
Die Matrix $R$ wird nun in das Produkt aus 2 Matrizen $P$ und $Q$ zerlegt, die multipliziert eine fast identische Matrix $\Tilde{R}$ ergeben:

\begin{equation*}
\underset{N \times N}{R} = \underset{N \times F}{P} \cdot \underset{F \times N}{Q} \approx  \underset{N \times N}{\Tilde{R}} 
\end{equation*}

Die Matrix $P$ mit Dimension $N \times F$ ergibt multipliziert mit $Q$ mit Dimensionen $F \times N$ wieder eine $N \times N$ Matrix. Nun werden sowohl $P$ als auch $Q$ mit zufälligen Werten initiiert und die Matrix $\Tilde{R}$ berechnet. Mithilfe des stochastischen Gradienten-Abstieg (mehr dazu in Kapitel \ref{kap:neuralNets}) wird nun der Inhalt von $P$ und $Q$ verändert, mit dem Ziel die Summe aller Einträge der Differenz von $\Tilde{R}$ und $R$ zu minimieren. Dies ist ein numerischer iterativer Prozess, der wiederholt wird, bis der Fehler eine vorgegebene untere Grenze erreicht. Die Matrix $P$ enthält nun die gewünschten \textit{word-embeddings} (vgl. \cite{keras}, S. 155f). Für eine detailierte Beschreibung der Methode sei auf \cite{glovePaper} verwiesen. Die Dimension $F$ der Wort-Vektoren muss vom Anwender festgelegt werden. Es ist möglich diese Vektoren auf dem vorliegenden Trainingsdatensatz zu trainieren, wenn der Textkorpus groß genug ist. In dem Fall des \textit{news category dataset} mit $200847$ ist dies durchaus plausibel. Das Trainieren der Vektoren erfolgte mit dem \texttt{R}-Paket \texttt{text2vec} (\cite{text2vec}) unter Verwendung der Parameter $skip\_grams\_window = 5$ für den symmetrischen Bereich des Kontextworts und die Dimension der Vektoren von $F = word\_vectors\_size = 50$.\\
Eine Alternative zum Training der \textit{word-embeddings} auf dem vorliegenden Textkorpus ist der Griff zu einem der vortrainierten Datensätze, die von \cite{gloveOnline} zur Verfügung gestellt worden sind. Diese Vektoren wurden auf massiven Datenmengen trainiert. Für diese Arbeit wurden 2 Datensätze mit vor-trainierten Wortvektoren des \textit{GloVe} Projekts genutzt: Ein auf Wikipedia mit $6$ Milliarden Dokumenten trainierter Datensatz mit einer Länge der Vektoren von $F = 50$ (\cite{gloveWiki}) und ein auf $42$ Milliarden aus dem Internet stammenden Textdokumenten mit $F = 300$ Dimensionen (\cite{gloveCommon}).\\

Ob nun vor-trainierte \textit{word embeddings} genutzt werden oder die Vektoren auf dem Trainingsdatensatz gelernt werden, es stellt sich die Frage, wie genau die Datenpunkte geformt werden, sodass ein \textit{machine learning} Modell immer Eingangswerte derselben Dimension erwarten kann. Nun ist unter der Annahme, dass eine Beobachtung immer aus einer Aneinanderreihung von Wörtern besteht, jeder durch Wort-Vektoren repräsentierter Datenpunkt $x_i$ bereits eine zweidimensionale Matrix mit Dimensionen $F \times  W_i$. $W_i$ steht für die Anzahl Wörter im Satz des Datenpunktes $x_i$ und $F$ ist die Anzahl der Wort-Vektoren. Damit die kodierten Datenpunkte nun jeweils die gleiche Dimension besitzen um zu einem dreidimensionalen Trainings-Array geformt werden zu können, soll $W_i$ immer gleich gewählt werden. Hier wird als Konstante $W_{max}$ die Anzahl Wörter gewählt, die $99.9$ Prozent der News Schlagzeilen im Trainingsset nicht überschreiten. Für jede Schlagzeile, die weniger Wörter als $W_{max}$ enthält, wird die Matrix für die fehlenden Wörter mit Nullen aufgefüllt (dies wird \textit{padding} genannt). Wäre $W_{max}$ die maximale Anzahl von Wörtern, die die größte Schlagzeile enthält, so würde durch das Auffüllen von vielen Nullen nur unnötig Speicherplatz verbraucht werden. \\

Allgemein haben die resultierenden Vektoren einige nützliche Eigenschaften. Als Ähnlichkeitsmaß zwischen 2 Vektoren kann das Kreuzprodukt genutzt werden. Wörter, die einander ähnlich sind, sind auch im $F$-dimensionalen Vektorraum nahe beieinander angeordnet. Falls die \textit{word-embeddings} auf großen Datenmengen trainiert worden sind, können die Vektoren sogar semantische Beziehungen repräsentieren. So kann beispielsweise \textit{walking} zu \textit{walked} dieselbe Beziehung haben wie \textit{swimming} zu \textit{swam}. Addiert oder subtrahiert man Wort-Vektoren, so können sogar Gleichungen der Form $king - man + women \approx queen$, oder $berlin - germany + france \approx paris$ zustande kommen (vlg. \cite{deepEssentials}, S. 122).

\subsubsection{Summe von Wort-Vektoren}

Die im vorherigen Abschnitt \ref{Kap:Glove} beschriebenen \textit{word-embeddings} bilden bei Sätzen immer eine zweidimensionale Matrix pro Datenpunkt. Es ist aber auch eine Dimensionsreduktion möglich indem die Vektoren unter bestimmten Regularisierungen summiert werden oder Differenzen gebildet werden. \cite{sumsWords}, S. 13 zeigen, dass die Summe der Word-Vektoren mit $L1$ Regularisierung eine gute Repräsentation der Sätze ist und gute Resultate liefert. Dies ist definiert als

\[SOW_{L1} = \frac{\sum_{i=1}^{W_{max}} \Vec{w_i}}{\| \sum_{i=1}^{W_{max}}  \vec{w_i} \|} \]
(\cite{sumsWords}, S. 5). Die $L1$ Norm skaliert die Einträge der $\Vec{w_i}$ so, dass die Summe aller Einträge $1$ entspricht. Es wird bis $W_{max}$ summiert, da das in Kapitel \ref{Kap:Glove} erläuterte \textit{padding} dafür sorgt, dass jede Schlagzeile mit genau $W_{max}$ Vektoren der Länge $F$ repräsentiert werden. Aufgrund der Auffüllung mit Nullen für fehlende Wörter beeinflusst dies den Summand nicht.
Jeder Datenpunkt wird zusammenfassend als Vektor mit $F$ Einträgen dargestellt, die die Bedeutung des dahinterstehenden Satzes im $F$ dimensionalen Raum repräsentieren.


\subsubsection{Sequentielle Darstellung} \label{Kap:Seq}

Eine weitere Möglichkeit, Sätze und Wörter zu repräsentieren ist als Sequenz von Indices. So bekommt jedes Wort eine natürliche Zahl aus dem Vokabular zugeordnet. Durch die Aneinanderreihung dieser Indices wird ein Satz als Sequenz von natürlichen Zahlen dargestellt. Die resultierende Datenmatrix hat also die Dimensionen $N \times W_{max}$, wobei $W_{max}$ analog wie in Kapitel \ref{Kap:Glove} gewählt wird. Diese kann als Trainingsdatensatz für ein klassisches \textit{machine-learning} Modell wie \textit{random Forest} (Kapitel \ref{kap:RF}), oder als Input für neuronale Netze wie \textit{CNN} (Kapitel \ref{kap:CNN}) oder \textit{LSTM} (Kapitel \ref{kap:LSTM}) dienen. Eine \textit{embedding} Eingangsschicht im neuronalen Netz lernt jeden Index dann zu einem Wort-Vektor einer vorgegebenen Größe $F$ und jeder Datenpunkt wird intern zu einer Matrix der Dimension $F \times W_{max}$ während des Trainieren des Netzes geformt. Das Bilden der \textit{word embeddings} geschieht in diesem Fall durch überwachtes Lernen und nicht durch unüberwachtes Lernen wie bei \textit{GloVe} in Kapitel \ref{Kap:Glove} (vgl. \cite{keras}, S.159f).\\
Die Erstellung der Wort-Sequenzen erfolgte in \texttt{R} mit dem Paket \texttt{keras} (\cite{kerasR}).\\

todo: zusammenfassung dieses Abschnitts schreiben (Mit Tabelle)


\subsection{\textit{machine learning} Modelle}

\subsubsection{Extreme Gradient Boosting}\label{kap:XG}
\subsubsection{Random Forest}\label{kap:RF}

\subsection{Neuronale Netze} \label{kap:neuralNets}

Dieser Abschnitt soll eine Einführung in das Gebiet der neuronalen Netze geben und die in dieser Arbeit verwendeten Architekturen erklären. Beginnend mit dem \textit{multi-layer-perceptron} Netz werden die allgemeinen Aspekte und Komponenten des \textit{deep learnings} erläutert. Daran anknüpfend werden mit dem Fokus auf \textit{natural language processing} (kurz \textit{NLP}, todo erklären) das \textit{convolutional neural net} und das \textit{long-short-term-memory neural net} beschrieben. Die Umsetzung im Programmiercode erfolgte mit dem \texttt{R}-Paket \texttt{keras} (\cite{kerasR}).


\subsubsection{Multi-Layer-Perceptron Neural Net}

Dieser Abschnitt basiert größtenteils auf \cite{deepEssentials}, S.60- todo).
Das \textit{Multi-Layer-Perceptron} (kurz \textit{MLP}) ist die einfachste Form eines neuronalen Netzes. Anhand des \textit{MLP} wird im Folgenden beschrieben, wie die Struktur und die Bestandteile eines neuronalen Netzes aussehen, wie es die Parameter lernt und welche Komponenten besonders wichtig sind für die erfolgreiche Anwendung. Abbildung \ref{abb:MLPScreen} zeigt die klassifische Struktur des \textit{MLP}:


\begin{figure}[!ht]
\begin{center}
\includegraphics[width = 10cm,  keepaspectratio]{Images/MLPScreenDeepLearningEssentials.PNG}
\label{abb:MLPScreen}
\caption{\textit{fully-connected feed-forward} Netz mit 2 Zwischenschichten  (\cite{deepEssentials}, S. 60) }
\end{center}
\end{figure}

Das Netz ist organisiert in verschiedenen Schichten, die jeweils aus Neuronen (auch Knoten oder Zellen genannt) bestehen. Die Eingangsschicht (\textit{input layer}) besteht meistens aus den als numerischen Werten kodierten Trainingsdaten und enthält entsprechend viele Neuronen. Darauf folgen mehrere Zwischenschichten (\textit{hidden layer}. Die Zwischenschichten können unterschiedliche Formen je nach Ziel und Architektur des Netzes haben und enthält oft eine vom Nutzer wählbare Anzahl von Neuronen. Die Ausgangsschicht (\textit{output layer}) schließt das Netz ab. Wieviele Knoten es enthält, ist abhängig von der Problemstellung. Im Falle einer Klassifikation mit $n$ Klassen enthält es ebenso viele Zellen. Nun bedeutet \textit{fully-connected}, dass jedes Neuron mit allen Neuronen aus der vorherigen und nachfolgenden Schicht verbunden ist. Die Verbindungslinien werden durch Gewichte repräsentiert, die den Einfluss des Eingangsneuron auf das Ausgangsneuron beschreiben. Bei einem \textit{feed-forward} Netz werden nur Signale in eine Richtung  zugelassen und zwar von Eingangs- bis Ausgangsschicht. Jede Schicht außer der Eingangsschicht besitzt in den Neurononen eine Aktivierungsfunktion, die bestimmt, welcher Anteil des Eingangssignal als Ausgangssignal weitergeleitet wird. Die Aktivierungsfunktion sollte differenzierbar sein, da das Netzwerk im Prozess des Lernens Gradienten berechnet. Dieser Aspekt soll später detailliert erläutert werden. Von der Vielzahl an verschiedenen Aktivierungsfunktionen werden folglich diejenigen vorgestellt, die in dieser Arbeit benutzten neuronalen Netze verwendet werden. Die \textit{rectified linear unit} (kurz \textit{relu}) hat in den letzten Jahren an Beliebtheit zugenommen.

\[\sigma(x) = 
\begin{cases}
max(0,x), & x >= 0 \\
0, & x <0
\end{cases}{}
\]

Es wurde gezeigt, dass Konvergenz unter Nutzung von \textit{relu} bis zu 6-Mal schneller erreicht werden kann. Außerdem benötigt ihre Berechnung weniger Rechenleistung als klassische Aktivierungsfunktionen. \textit{relu} wird heutzutage aus diesen Gründen in den meisten neuronalen Netzen in den Zwischenschichten verwendet. Da die Ausgangssignale nicht im Wahrscheinlichkeitsintervall $\left[0, 1\right]$ liegt, kann sie nicht für die Ausgangsschicht verwendet werden. Hierbei wird im Klassifikationsfall zur \textit{softmax} Aktivierungsfunktion gegriffen. 

\[p(y = j |z_j) = \phi(z_j) = \frac{e^{z_j}}{\sum_j^n z_j} \]

Hierbei bezeichnet $z_j$ das Ausgangssignal des Neurons der $j$-ten Klasse und $y$ die wahre Klasse. $\phi$ normiert die Ausgangssignale für jedes der $n$ Neuronen in der Ausgangsschicht und modelliert für jede der Klassen eine Art Wahrscheinlichkeit in $\left[0, 1\right]$. Insgesamt ergibt sich $\sum_{j = 1}^n \phi(z_j) = 1$. Für die in dieser Arbeit verwendeten neuronalen Netze wird jeweils eine Ausgangsschicht mit $n = 35$ Knoten gewählt und die \textit{softmax} Aktivierungsfunktion zur Transformation der Eingangssignale genutzt.\\
\\
Nachdem nun die grundlegende Architektur des Netzwerkes und die Aktivierungsfunktionen erläutert wurden, soll nun der Lernprozess durch den Gradientenabstieg und die damit verbundene Anpassung der Gewichte beschrieben werden.\\

Die Optimierung des Netzwerkes geht insofern von statten, dass die Funktion $f(x)$ bezüglich einer Verlustfunktion minimiert wird, indem $x$ geändert wird. Der Wert, der $f$ minimiert, wird notiert als 
\[x^\ast = argmin f(x)\]
Seien $x, y = f(x) \in \mathbb{R}$, so ist $f'(x) = \frac{\mathop{dx}}{\mathop{dy}}$ die Steigung in $x$ und gibt an, in was für einer Änderung $f(x)$ bei einer kleinen Änderung von $x$ resultiert. Unter Kenntnis von $f'(x)$ kann $f(x)$ schrittweise durch eine Änderung von $x$ in die Gegenrichtung der Ableitung minimiert werden. Diese Methode ist bekannt als Gradientenabstieg. Ist $f'(x) = 0$, so handelt es sich entweder um ein Minimum, Maximum oder einen Sattelpunkt. Ziel des Gradientenabstieg ist es, ein globales Minimum zu finden. Es ist möglich, dass die Funktion auch einige lokale Minima besitzt, die in denen $f(x)$ in einer gewissen Umgebung am kleinsten ist. Das Vorliegen von mehreren Sattelpunkten und lokalen Minima macht die Optimierung sehr schwierig, besonders, da es sich in der Praxis um multidimensionale Optimierungen handelt. Oft werden solche Lösungen akzeptiert, die nicht global minimal sind, aber einen signifikant niedrigen Wert der Verlustfunktion aufweisen. Abbildung \ref{abb:MinimaSearch} zeigt eine beispielhafte Darstellung einer eindimensionalen Verlustfunktion mit verschiedenen Minima und Sattelpunkten.

\begin{figure}[!ht]
\begin{center}
\includegraphics[width = 10cm,  keepaspectratio]{Images/MinimaSearch_DeepL.PNG}
\label{abb:MinimaSearch}
\caption{\textit{Darstellung von lokalen und globalen Minima sowie Sattelpunkten bei der Optimierung einer eindimensionalen Funktion (\cite{deepL}, S. 85)}}
\end{center}
\end{figure}

Die Verlustfunktion ist in Abhängigkeit des Parameter-Vektors $\theta$ meistens nicht-linear und nicht-konvex, wie beispielsweise in Abbildung \ref{abb:MinimaSearch} zu sehen ist. Oft ist es möglich, dass der Gradientenabstieg in einem ungenügenden lokalen Minimum endet. Verschiedene Optimierungsalgorithmen versuchen dieses Problem zu lösen und werden im weiteren Verlauf dieses Kapitels beschrieben.\\

Ist $\bm{x} = (x_1, ..., x_l)$, ein Vektor mit $l$ Dimensionen, so werden partielle Ableitungen $\frac{\partial}{\partial x_i} f(\bm{x})$ gebildet, die die Richtungsänderung von $f$ darstellt, wenn nur $x_i$ in $\bm{x}$ modifiziert wird. Der Vektor aller partiellen Ableitungen $(\frac{\partial f(\bm{x})}{\partial x_i}, \dots, \frac{\partial f(\bm{x})}{\partial x_l)})$ ist der Gradient von $f$ und wird notiert als $\nabla_{\bm{x}} f(\bm{x})$ (vgl. \cite{deepL}, S.82 ff).\\

Nun soll die Methode des Gradientenabstiegs an einem einfachen Beispiel erläutert werden. In einem Netzwerk mit 2 Zwischenschichten sei $(\bm{x_0}, \bm{y})$ der Eingangsvektor und die zugehörige abhängige Variable sowie $(\bm{w_1}, \bm{b_1})$, $(\bm{w_2}, \bm{b_2})$ die Vektoren der Verbindungsgewichte und \textit{bias} der Zwischenschichten. Der erste Schritt ist die Initialisierung der Gewichte und der \textit{bias} Parameter. Die Gewichte werden mit kleinen zufällige Werten initialisiert und die \textit{bias} Parameter entweder auf $0$ gesetzt oder auch mit kleinen positiven Zufallszahlen belegt (vgl. \cite{deepL}, S. 177). Eine Ausnahme stellt die Nutzung eines vortrainierten Netzes dar, das bereits gelernte Gewichte enthält. Als nächstes werden die Eingangsvektoren im Rahmen der \textit{forward-propagation} vorwärts durch das Netz geleitet. Die Berechnung erfolgt sukzessive mit
\begin{align*}
    \bm{z_1} &= \bm{x_0} \cdot \bm{w_1} + \bm{b_1} \\
    \bm{a_1} &= \sigma(\bm{z_1}) \\
    \bm{z_2} &= \bm{a_1} \cdot \bm{w_2} + \bm{b_2} \\
    \bm{a_2} &= \sigma (\bm{z_2})
\end{align*}{}
$\bm{z_1}, \bm{z_2}$ sind die Vektoren, die in den Zwischenschichten eintreffen und $\bm{a_1}, \bm{a_2}$ die Signale, die die Neuronen der Zwischenschichten wieder verlassen. Anschließend wird der Fehler des Netzwerkes berechnet mit 
\[\nabla \bm{a} = \bm{a_2} - \bm{y} \].
In diesem Beispiel wird die Verlustfunktion aus der Differenz des Ausgangssignales des letzten \textit{layers} und des Labels $y$ gebildet. Die Verlustfunktion ist natürlich je nach Zielstellung als eine andere zu wählen. Nun werden im Rahmen der \textit{backpropagation} die Gradienten berechnet:

% bei align sind zeilen wichtig
\begin{align*}
    \nabla \bm{z_2} &= \nabla \bm{a} \cdot \sigma' (\bm{z_2}) \\
    \nabla \bm{b_2} &= \nabla \bm{z_2} \\
    \nabla \bm{w_2} &= a_1^T \cdot \nabla \bm{z_2} \\
    \nabla \bm{z_1} &= \nabla \bm{a_1} \cdot \sigma (\bm{z_1}) \\
    \nabla \bm{b_1} &= \nabla \bm{z_1} \\
    \nabla \bm{w_1} &= a_0^T \cdot \nabla \bm{z_1} 
\end{align*}{}

Anschließend werden die Parameter des Netzwerkes wie folgt angepasst:

\begin{align*}
   \bm{w_1} &\leftarrow \bm{w_1} - \eta \cdot \nabla \bm{w_1} \\
\bm{b_1} &\leftarrow \bm{b_1} - \eta \cdot \nabla \bm{b_1} \\
 \bm{w_2} &\leftarrow \bm{w_2} - \eta \cdot \nabla \bm{w_2} \\
    \bm{b_2} &\leftarrow \bm{b_2} - \eta \cdot \nabla \bm{b_2} \\
\end{align*}{}

Die Gewichte und \textit{bias} werden also in die negative Richtung ihrer partiellen Ableitung angepasst. Wie groß der Schritt des Abstiegs ist, bestimmt die Lernrate $eta$. 
Wie genau $\eta$ bestimmt wird, hängt unter anderem vom dem verwendeten Optimierungsalgorithmus ab. Für die Durchführung der Methode des Gradientenabstiegs gibt es mehrere Varianten. Es wird davon abgesehen, den Gradienten mit allen Beobachtungen des Datensatzes zu berechnen. Dies ist sehr rechenintensiv und ineffizient in dem Sinne, dass in einem schlechten Szenario die Beobachtungen sehr ähnlich sind und eine kleine Auswahl der Datenpunkte zu einer ähnlichen Verbesserung der Verlustfunktion beiträgt wie unter Nutzung aller Datenpunkte. Auch wenn dies ein Extremfall ist, finden sich oft viele Beobachtungen, die ähnlich zur Berechnung des Gradienten beitragen. Optimierungsalgorithmen konvergieren in der Regel in einer schnelleren Rechenzeit, falls sie schnell hintereinander ungefähre Schätzungen des Gradienten erstellen, statt langsam den gesamten Gradienten zu berechnen. Methoden, die jeweils nur eine Beobachtung nutzen um den neuen Gradienten zu berechnen, werden als Stochastische Methoden bezeichnet. Optimierungsalgorithmen, die den kompletten Trainingsdatensatz nutzen, werden als \textit{batch} oder deterministische Gradienten Methoden bezeichnet. Das Wort \textit{batch} wird jedoch auch in dem anderen Kontext von \textit{batch}-Größe genutzt, um die Größe des \textit{minibatch} bei der Methode \textit{minibatch-stochastic-gradient-descent} zu beschreiben. Hierbei bezeichnet die \textit{batch}-Größe $m$ die Anzahl Datenpunkte aus dem Trainingsset, die herangezogen werden um die Gewichte des neuronalen Netzes in einem Schritt zu aktualisieren (vgl. \cite{keras}, S.19). Diese Methode ist ein Kompromiss aus \textit{batch}- und stochastischem Gradientenabstieg und wird bei von den meisten \textit{deep-learning}-Algorithmen genutzt. Die \textit{minibatch} Methode wird heutzutage einfach als \textit{stochastischer} Methode bezeichnet (vgl. \cite{deepL}, S. 279f). Nun gibt es viele \textit{minibatch} Optimierungsmethoden, die mit der Zeit immer verbesserte Ansätze zur Bildung der Lernrate $\eta$ lieferten. Die in dieser Thesis verwendete \textit{adam}-Methode nutzt adaptive Lernraten und kombiniert die Konzepte des Momentums und der Beschleunigung bei der Anpassung der Gewichte nach jedem Optimierungsschritt. \textit{adam} liefert verglichen mit anderen Methoden sehr gute Ergebnisse (vgl. \cite{keras}, S. 36). Für eine detaillierte Einführung in die Evolution der Optimierungsmethoden sei auf Kapitel 8 in \cite{deepL} verwiesen. Eine weitere Herausforderung für die erfolgreiche Anwendung eines neuronalen Netzes ist die Eigenschaft, dass das Netz nicht nur auf den Trainingsdaten gut abschneidet, sondern auch auf neuen Daten eine gute Vorhersage liefert. Ist das Gegenteil der Fall, so betreibt das Netz \textit{overfitting} und kann schlecht generalisieren. Strategien, die das Ziel dieser wünschenswerten Eigenschaft verfolgen, werden Regularisierungstechniken genannt. Eine effektive Methode, um \textit{overfitting} zu vermeiden, ist die Nutzung von \textit{dropout}. Hierbei wird während einer Trainings-Iteration eines \textit{minibatch} zufällig ein gewisser prozentualer Anteil der Eingangs-Neuronen einer Schicht auf $0$ gesetzt. Damit wird erzielt, dass verschiedene Fraktionen des Netzes aus unterschiedlicher Information lernen. So kann das Netz besser generalisieren, da während des Lernprozesses effizient mehrere Teil-Architekturen des Netzes kombiniert werden (vgl. \cite{deepEssentials}, S. 71). In dem Paket \texttt{keras} kann \textit{dropout} einfach implemtiert werden, indem zwischen den Schichten eine \textit{dropout} Schicht eingefügt wird (vgl. \cite{keras}, S. 68).

\begin{itemize}
    \item kostenfunktion bei multiclassifikation
    \item vanishing gradient problem (bei relu eingehen?
    \item batch normalization
    \item dead neurons, lieber leaky relu?
\end{itemize}{}



\subsubsection{Convolutional Neural Net} \label{kap:CNN}
\subsubsection{Long-Short-Term-Memory Neural Net} \label{kap:LSTM}

\begin{itemize}
    \item grafik über kombination von word embeddings und Algorithmen (was kann mit was verwendet werden)
\end{itemize}{}





\end{document}{}